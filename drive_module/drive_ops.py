#drive_ops.py

import streamlit as st
import re
from .auth import get_drive_service
from googleapiclient.http import MediaIoBaseDownload
import io
import yaml


def get_file_id_from_link(url):
    try:
        start = url.index("/d/") + 3
        end = url.index("/view", start)
        return url[start:end]
    except ValueError:
        return None

def get_images_in_folder(folder_id):
    """
    Tr·∫£ v·ªÅ danh s√°ch c√°c file ·∫£nh trong th∆∞ m·ª•c, m·ªói ph·∫ßn t·ª≠ l√† tuple (name, file_id).
    C√°c ·∫£nh c√≥ MIME type b·∫Øt ƒë·∫ßu b·∫±ng 'image/'.
    """
    all_files = list_folder_contents(folder_id)
    image_files = [
        (f["name"], f["id"])
        for f in all_files
        if f["mimeType"].startswith("image/")
    ]
    return image_files

def get_or_cache_data(key, loader_func, dependencies=None):
    dep_key = f"{key}__deps"
    if key in st.session_state and dep_key in st.session_state:
        if st.session_state[dep_key] == dependencies:
            return st.session_state[key]
    data = loader_func()
    st.session_state[key] = data
    st.session_state[dep_key] = dependencies
    return data


def extract_bullet_items_from_section(content, section_name):

    # T√¨m ph·∫ßn gi·ªØa ## {section_name}: v√† ## ti·∫øp theo ho·∫∑c h·∫øt file
    pattern = rf"##\s*{re.escape(section_name)}\s*:\s*(.*?)(?=\n##\s|\Z)"
    match = re.search(pattern, content, re.DOTALL | re.IGNORECASE)

    if not match:
        return []

    block = match.group(1)

    # L·∫•y c√°c d√≤ng b·∫Øt ƒë·∫ßu b·∫±ng d·∫•u g·∫°ch ƒë·∫ßu d√≤ng '-'
    lines = block.strip().splitlines()
    bullet_lines = [line.strip() for line in lines if line.strip().startswith("-")]

    return bullet_lines

def extract_yaml(content):

    match = re.search(r'^---\s*(.*?)\s*---', content, re.DOTALL | re.MULTILINE)
    if not match:
        st.error("‚ùå Kh√¥ng t√¨m th·∫•y YAML front matter.")
        return {}

    try:
        data = yaml.safe_load(match.group(1))
        return data or {}
    except yaml.YAMLError as e:
        st.error(f"‚ö†Ô∏è L·ªói khi ph√¢n t√≠ch YAML: {e}")
        return {}

def deep_update(d, u):
    """Merge dict u v√†o dict d, gi·ªØ t·∫•t c·∫£ key, merge dict v√† list s√¢u"""
    for k, v in u.items():
        if k in d:
            if isinstance(d[k], dict) and isinstance(v, dict):
                deep_update(d[k], v)
            elif isinstance(d[k], list) and isinstance(v, list):
                d[k].extend(x for x in v if x not in d[k])  # append nh∆∞ng tr√°nh tr√πng
            else:
                d[k] = v  # ghi ƒë√® n·∫øu kh√¥ng c√πng type
        else:
            d[k] = v
    return d


def extract_yamls(datas):
    """
    Tr√≠ch xu·∫•t YAML t·ª´ nhi·ªÅu file v√† merge l·∫°i th√†nh m·ªôt dict duy nh·∫•t.
    N·∫øu c√πng key, d·ªØ li·ªáu s·∫Ω ƒë∆∞·ª£c g·ªôp v√†o thay v√¨ ghi ƒë√®.
    """
    merged = {}
    for raw_data in datas:
        data = extract_yaml(raw_data)
        if data:
            deep_update(merged, data)
    return merged



def get_file_content(file_id):
    """ƒê·ªçc n·ªôi dung file t·ª´ Google Drive (d·∫°ng vƒÉn b·∫£n)."""
    request = drive_service.files().get_media(fileId=file_id)
    fh = io.BytesIO()
    downloader = MediaIoBaseDownload(fh, request)

    done = False
    while not done:
        status, done = downloader.next_chunk()

    return fh.getvalue().decode("utf-8")

def extract_folder_id_from_url(url: str) -> str:
    """Tr√≠ch xu·∫•t folder ID t·ª´ URL Google Drive."""
    match = re.search(r"/folders/([a-zA-Z0-9_-]+)", url)
    if not match:
        return None
    return match.group(1)

def select_working_folder():
    """Hi·ªÉn th·ªã √¥ nh·∫≠p URL th∆∞ m·ª•c ·ªü sidebar v√† tr·∫£ v·ªÅ folder ID."""
    with st.sidebar:
        url = st.text_input("üîó Nh·∫≠p link th∆∞ m·ª•c Google Drive (Working Folder)")

    folder_id = extract_folder_id_from_url(url) if url else None

    if url and not folder_id:
        st.sidebar.warning("‚ùå Link kh√¥ng h·ª£p l·ªá. Link ph·∫£i c√≥ d·∫°ng ch·ª©a /folders/<ID>")

    return folder_id

def list_folder_contents(folder_id, parent = None):

    # L·∫•y danh s√°ch file/folder con
    query = f"'{folder_id}' in parents and trashed = false"
    fields = "files(id, name, mimeType, parents, modifiedTime)"
    results = drive_service.files().list(q=query, fields=fields).execute()
    files = results.get("files", [])

    return files



def list_folder_contents_recursive(folder_id):

    # L·∫•y c√°c item tr·ª±c ti·∫øp trong folder hi·ªán t·∫°i
    items = list_folder_contents(folder_id, 1)

    all_items = []
    for item in items:
        all_items.append(item)  # lu√¥n th√™m ch√≠nh item ƒë√≥ v√†o danh s√°ch

        # N·∫øu item l√† folder => g·ªçi ƒë·ªá quy ƒë·ªÉ l·∫•y ti·∫øp n·ªôi dung
        if item.get("mimeType") == "application/vnd.google-apps.folder":
            sub_items = list_folder_contents_recursive(item["id"])
            all_items.extend(sub_items)

    return all_items

def build_tree(items):
    tree = {}

    # Kh·ªüi t·∫°o t·∫•t c·∫£ folder
    for item in items:
        if item["mimeType"] == "application/vnd.google-apps.folder":
            tree[item["id"]] = {
                "name": item["name"],
                "files": [],
                "subfolders": []
            }
    root = set()
    # G·∫Øn file v√† subfolder v√†o ƒë√∫ng folder cha
    for item in items:
        parents = item.get("parents", [])
        if not parents:
            continue
        parent_id = parents[0]
        if parent_id not in tree:
            root.add(parent_id)
            continue

        if item["mimeType"] == "application/vnd.google-apps.folder":
            tree[parent_id]["subfolders"].append(item["id"])
        elif item["mimeType"] == "text/markdown":
            tree[parent_id]["files"].append(item["id"] + "|" + item["modifiedTime"] + "|" + item["name"])
    root_id = list(root)[0]
    tree[root_id] = {
        "name": "ROOT",
        "files": [],
        "subfolders": list(tree.keys())
    }
    return tree




def collect(folder, tree, checkbox, memo=None, folder_all_files=None):
    if memo is None:
        memo = {}
        folder_all_files = {}
        
    contents = []
    all_files = []
    for file in tree[folder].get("files", []):
        if file.endswith(".md"):          # ch·ªâ x·ª≠ l√Ω file k·∫øt th√∫c b·∫±ng .md
            fikle_attribute = file.split("|")
            file_content = get_or_cache_data(
                key=f"folder_contents_{file}",
                loader_func=lambda: get_file_content(fikle_attribute[0]),
                dependencies={"sorted_compo_id": fikle_attribute[1]}
            )
            all_files.append(file)
            contents.append(file_content)

    for sub in tree[folder]["subfolders"]:
        sub_contents, memo, fol, folder_all_files = collect(sub, tree, checkbox, memo, folder_all_files)
        contents.extend(sub_contents)
        all_files.extend(fol)

    memo[folder] = contents
    folder_all_files[folder] = all_files
    return contents, memo, all_files, folder_all_files

drive_service = get_drive_service()
